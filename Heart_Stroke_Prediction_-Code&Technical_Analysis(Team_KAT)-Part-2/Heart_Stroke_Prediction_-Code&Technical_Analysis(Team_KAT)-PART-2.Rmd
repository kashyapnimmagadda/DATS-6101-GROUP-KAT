---
title: "Heart Stroke Prediction - Code & Technical Analysis, Part - 2"
author: "Team KAT"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: TRUE
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r basic_libraries, include=FALSE}

# Importing required libraries for the EDA.
library(ezids)
library(ggplot2)
library(tidyverse)
library(conflicted)
library(dplyr)
library(rpart)
library(rpart.plot)
library("pROC")
library(DMwR)
library(caret)
library(ROSE)
library(car)
library(randomForest)

```


# Introduction
Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. 

Most cardiovascular diseases can be prevented by addressing behavioral risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity using population-wide strategies.

This dataset contains 14 features that can be used to predict mortality by heart failure.

Reference: https://www.who.int/en/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds)

## Source of the dataset

This heart stroke dataset is from kaggle platform. The variables are:  

Variable |  Definition  
  :-:    |  :-- 
male	 | Patient sex (Gender) | Male - 0, Female - 1 (Categorical)
age | Patient age (Numerical)
education | Patient education level (Numerical)
currentSmoker | No - 0, Yes - 1
cigsPerDay | Number of cigarettes consumed by the person (Numerical)
BPMeds | If under Medication for BP | No - 0, Yes - 1 (Categorical)
prevalentStroke | Patient history of heart stroke | No - 0, Yes - 1 (Categorical)
prevalentHyper | Patient history of hypertension | No - 0, Yes - 1 (Categorical)
diabetes | Patient history of diabetes | No - 0, Yes - 1 (Categorical)
totChol | Patient cholestrol level (Numerical)
sysBP | Patient systolic blood pressure level (Numerical)
diaBP | Patient systolic blood pressure level (Numerical)
BMI | Patient body mass index value (Numerical)
heartRate | Patient heart rate value (Numerical)
glucose | Patient glucose level (Numerical)
stroke (Target variable) | Patient stroke chance (Ten year risk of coronary heart disease) | No - 0, Yes - 1 (Categorical)

Source link: https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression

```{r load_csv, include=TRUE, echo=TRUE}
github_file_path <-
  "https://raw.githubusercontent.com/kashyapnimmagadda/DATS-6101-GROUP-KAT/main/DataSet/framingham.csv"
stroke_df <- read.csv(url(github_file_path))
```

## Sample record elements of stroke dataframe


```{r head_2_csv, include=TRUE, echo=TRUE}
head(stroke_df, n = 5)
```

# Summary of the dataset
```{r data_cleaning, include=TRUE, echo=TRUE}

names(stroke_df)[names(stroke_df) == "TenYearCHD"] <- "stroke"
colnames(stroke_df)[1] <- "gender"

stroke_df$gender[stroke_df$gender == "0"] <- "F"
stroke_df$gender[stroke_df$gender == "1"] <- "M"

# converting the numeric variables to factor variables
stroke_df$gender <- as.factor(stroke_df$gender)
stroke_df$currentSmoker <- as.factor(stroke_df$currentSmoker)
stroke_df$BPMeds <- as.factor(stroke_df$BPMeds)
stroke_df$prevalentStroke <- as.factor(stroke_df$prevalentStroke)
stroke_df$prevalentHyp <- as.factor(stroke_df$prevalentHyp)
stroke_df$diabetes <- as.factor(stroke_df$diabetes)
stroke_df$stroke <- as.factor(stroke_df$stroke)
stroke_df$BMI <- as.numeric(stroke_df$BMI)

# To get the summary statistics of the dataset
summary(stroke_df)

```

# Data Cleaning - Checking for null values
```{r find_na_fix, include=TRUE, echo=TRUE}
paste("The NA's in the dataset is:", sum(is.na(stroke_df)))
```

```{r na_fix, include=TRUE, echo=TRUE}
# Replacing cigsPerDay NA values with mean value
stroke_df$cigsPerDay[is.na(stroke_df$cigsPerDay)] <-
  mean(stroke_df$cigsPerDay, na.rm = TRUE)

# Replacing Education NA values with mean value
stroke_df$education[is.na(stroke_df$education)] <-
  mean(stroke_df$education, na.rm = TRUE)
stroke_df$education <- as.integer(stroke_df$education)

# Replacing BPMeds NA values with mean value
# stroke_df$BPMeds[is.na(stroke_df$BPMeds)] = mean(stroke_df$BPMeds, na.rm = TRUE)
# stroke_df$BPMeds <- as.integer(stroke_df$BPMeds)
stroke_df$BPMeds[is.na(stroke_df$BPMeds)] <- 0



# Replacing HeartRate NA values with mean value
stroke_df$heartRate[is.na(stroke_df$heartRate)] <-
  mean(stroke_df$heartRate, na.rm = TRUE)


# Replacing NA values with average BMI value
stroke_df$BMI[is.na(stroke_df$BMI)] <-
  mean(stroke_df$BMI, na.rm = TRUE)


# Replacing NA values with average glucose value
stroke_df$glucose[is.na(stroke_df$glucose)] <-
  mean(stroke_df$glucose, na.rm = TRUE)


# Replacing NA values with average totChol value
stroke_df$totChol[is.na(stroke_df$totChol)] <-
  mean(stroke_df$totChol, na.rm = TRUE)


paste("The NA's in the dataset after replacing null values is:", sum(is.na(stroke_df)))
```

## Summary after data-cleaning
```{r summary_after cleaning}
# To get the summary statistics of the dataset

xkablesummary(stroke_df,
  title = "Table : Statistical Summary after cleaning",
  pos = "center",
  bso = "hover"
)
```


```{r subsets, include=TRUE, echo=TRUE}

# subsetting the data for various analyses
stroke_1 <- subset(stroke_df, stroke == 1)
stroke_0 <- subset(stroke_df, stroke == 0)
stroke_1_female <- subset(stroke_df, stroke == 1 & gender == "F")
stroke_1_male <- subset(stroke_df, stroke == 1 & gender == "M")

# creating different columns for bmi, age and average_glucose_level based on different bucketing for each variables
dat <- within(stroke_df, {
  BMI.cat <- NA # need to initialize variable
  BMI.cat[BMI < 18.5] <- "underweight"
  BMI.cat[BMI >= 18.5 & BMI < 25] <- "normal"
  BMI.cat[BMI >= 25 & BMI < 30] <- "overweight"
  BMI.cat[BMI >= 30 & BMI < 40] <- "obesity"
  BMI.cat[BMI >= 40] <- "severe obesity"

  gluc.cat <- NA # need to initialize variable
  gluc.cat[glucose < 60] <- "Below 60"
  gluc.cat[glucose >= 60 & glucose < 90] <- "60 - 90"
  gluc.cat[glucose >= 90 & glucose < 120] <- "90 - 120"
  gluc.cat[glucose >= 120 & glucose < 180] <- "120 - 180"
  gluc.cat[glucose >= 180 & glucose < 273] <- "180 - 273"
  gluc.cat[glucose >= 273] <- "Beyond 273"

  age.cat <- NA
  age.cat[age <= 20] <- "Under 20"
  age.cat[age >= 21 & age <= 40] <- "20-40"
  age.cat[age >= 41 & age <= 60] <- "40-60"
  age.cat[age >= 61 & age <= 80] <- "60-80"
  age.cat[age >= 80] <- "above 80"
})

dat$BMI.cat <-
  factor(
    dat$BMI.cat,
    levels = c(
      "underweight",
      "normal",
      "overweight",
      "obesity",
      "severe obesity"
    )
  )
dat$gluc.cat <-
  factor(dat$gluc.cat,
    levels = c("Below 60", "60 - 90", "90 - 120", "120 - 180", "180 - 273")
  )
dat$age.cat <-
  factor(dat$age.cat,
    levels = c("Under 20", "20-40", "40-60", "60-80", "above 80")
  )

dat_1 <- subset(dat, stroke == 1)
```

<<<<<<< Updated upstream

```{r}
install.packages("reshape2")
=======
# Correlation matrix for numeric variables

```{r correlation_matrix, echo = TRUE}

>>>>>>> Stashed changes
library(reshape2)
 
# creating correlation matrix
corr_mat <- round(cor(stroke_df[, sapply(stroke_df, is.numeric)]),2)
 
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
head(melted_corr_mat)
 
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,
                                   fill=value)) +
geom_tile() +
geom_text(aes(Var2, Var1, label = value),
          color = "black",size=4)
```


# Plots
## Univariate analysis.

### Density plot of Age
```{r variable_dist_age, include=TRUE, echo=TRUE}

ggplot(stroke_df, aes(x=age)) +
    geom_density(colour="white", fill="yellow",alpha=0.5) +
    geom_vline(aes(xintercept=mean(age, na.rm=T)),   # Ignore NA values for mean
               color="red", linetype="dashed",size=1) +
  ggtitle("Distribution for age")

```

This density plot is showing a smooth line which represents the density of age values in our dataset. The higher the peak of the line, the more values there are in that range. Conversely, the lower the peak, the fewer values there are in that range. From this plot, 


### Density plot for BMI
```{r variable_dist_BMI, include=TRUE, echo=TRUE}
ggplot(stroke_df, aes(x = BMI)) +
  geom_density(
    fill = "black",
    color = "#6A3D9A",
    alpha = 0.5
  ) +geom_vline(aes(xintercept=mean(BMI, na.rm=T)),   # Ignore NA values for mean
               color="#FEB6DB", linetype="dashed",size=1)
  theme_bw() +
  theme() +
  ggtitle("Distribution for BMI")
```

This density plot depicts a smooth line which represents the density of BMI values in our dataset. The higher the peak of the line, the more values there are in that range. Conversely, the lower the peak, the fewer values there are in that range. From this plot, within the BMI range of 20 to 30, with a peak value of 25 BMI, more observations are recorded.

### Density plot for glucose
```{r variable_dist_glucose, include=TRUE, echo=TRUE}
ggplot(stroke_df, aes(x = glucose)) +
  geom_density(
    fill = "brown",
    color = "brown",
    alpha = 0.5
  ) +geom_vline(aes(xintercept=mean(glucose, na.rm=T)),   # Ignore NA values for mean
               color="black", linetype="dashed",size=1)
  ggtitle("Distribution for Glucose Level") +
  theme_bw()+theme()
```


The above density plot represents the distribution of glucose level of all the patients in the dataset. From this density curve, majority of the observations are recorded below the glucose level of 100 with a peak value at 90.

### Bar plot to count the number of Males and Females in the Dataset
```{r variable_dist_gender, include=TRUE, echo=TRUE}
ggplot(stroke_df, aes(x = gender, fill = gender)) +
  geom_bar() +
  ggtitle("Count of Male and Female in the Dataset") +
  theme_bw() +
  theme() +
  xlab("Gender") +
  ylab("Count of people") +
  scale_fill_discrete(name = "gender", labels = c("F - Female", "M - Male"))
```

This bar chart represents the gender distribution of all the patients in the dataset. It shows the count of male and female patients. We have around 2400 female records and 1800 male records in the dataframe.

## Distribution of the target variable (stroke)
```{r target_var, include=TRUE, echo=TRUE}
ggplot(stroke_df, aes(x = stroke)) +
  geom_bar(aes(fill = ..count..)) +
  scale_fill_gradient("Count", low = "#F0E442", high = "#999999") +
  labs(x = "stroke", y = "Count of People", title = "Distribution of Target variable (stroke)")
```

This bar plot illustrates the distribution of the target variable (stroke - which means the ten year risk of coronary heart disease). Labels represents 0 - as records of people with no-stroke and 1 - as records of people with stroke. From the graph, it is shown as the dataset we have is imbalanced data which address our 2nd smart question - which leads further investigations and modifying the data using sampling techniques such as under-sampling and over-sampling.


## Multi-Variate analysis.
### BMI vs stroke 
```{r}
ggplot(stroke_1, aes(x = BMI, 
                     fill = stroke)) +
  geom_histogram(
    color = "#e9ecef",
    alpha = 0.6,
    position = "identity", 
  ) +
  theme_bw() +
  theme() +
  ggtitle("BMI vs Stroke") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

This box plot is plotted between BMI and the number of persons affected by heart stroke. According to the graph, those with BMIs ranging from 20 to 30 are the more people who effected by the heart attack.

### Does it depend based on the gender?
```{r gender_smoking, include=TRUE, echo=TRUE}
# seeing if gender has any affect on stroke based on smoking and Age
ggplot(stroke_1_female, aes(x = age, fill = currentSmoker)) +
  geom_bar(position = "dodge") +
  ggtitle("Distribution of females who had a stroke based on their smoking habits") +
  theme_bw() +
  theme() +
  xlab("Age") +
  ylab("Count of people ")


ggplot(stroke_1_male, aes(x = age, fill = currentSmoker)) +
  geom_bar(position = "dodge") +
  ggtitle("Distribution of males who had a stroke based on their smoking habits") +
  theme_bw() +
  theme() +
  xlab("Age") +
  ylab("Count of people ")
```


As seen in the graph above, the key causes that caused a stroke in females were never smoked and it may be dependent on other variables. 

Whereas in males, the reason for stroke was due to the current smoking habit.

### Does age has significant effect on the stroke?
```{r age_stroke_1, include=TRUE, echo=TRUE}
# seeing if age has effect in stroke

ggplot(stroke_1, aes(x = age, fill = stroke)) +
  geom_density(alpha = 0.3) +
  ggtitle("Density plot for age of people who had stroke") +
  theme_bw() +
  theme() +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

In general, we know that as one gets older, the likelihood of contracting an illness increases. 

We wanted to see if this statement held true with our dataset. The above graph clearly shows that as one's age grows, the likelihood of having a stroke increases.

### Does BMI with age cause stroke?
```{r age_bmi, include=TRUE, echo=TRUE}
# how bmi and age is stroke in people
ggplot(stroke_1, aes(x = BMI, y = age, color = stroke)) +
  geom_boxplot(size = 3) +
  ggtitle("Scatter plot for age vs bmi for people who had a stroke") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```


This box plot is plotted between age and BMI, according to the graph, those in the age range of 50 to 60 and BMI (body mass index) range of 30 to 40 are the most affected by heart stroke.

The categories are encoded as:

- Underweight - BMI < 18.5
- Normal - BMI >= 18.5 and BMI <= 25
- Overweight - BMI >= 25.0 and BMI <= 30
- Obesity - BMI >= 30.0 and BMI < 40
- "Extreme" or Severe Obesity - BMI >= 40 


### BMI-categories vs Age.
```{r age_bmi.cat, include=TRUE, echo=TRUE}
dat_1 <- subset(dat, stroke == 1)

# boxplot to see if bmi along with age has anything to do with stroke
ggplot(dat_1, aes(x = BMI.cat, y = age, fill = stroke)) +
  geom_boxplot() +
  ggtitle("Boxplot for Age vs BMI(categorical)") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```


This box plot that we plotted for BMI and the age and filled by who effected with heart stroke. 

We converted BMI as a categorical variable into several groups like (underweight, normal, overweight,obesity,severe obesity) as per our observation the people who are in the overweight category and age range of 50 -65 years are the most people who had influenced heart attack.

### Does age with glucose level affect stroke?
```{r age_glucose, include=TRUE, echo=TRUE}
# seeing if average glucose level with age has an effect on stroke

ggplot(dat_1, aes(fill = stroke, y = age, x = gluc.cat)) +
  geom_boxplot() +
  ggtitle("Boxplot for Age vs Gluclose level(Categorical) for people with stroke") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

The box plot is for the combination of age versus gluclose, where the gluclose variable is translated as a categorical variable into several categories like as (Below 60, 60-90, 90-120, 180-273). 

Those with gluclose levels above 90 and ages 50 to 60 are more likely to have a heart attack.

### Does age cause hypertension?
```{r age_hypertension, include=TRUE, echo=TRUE}
# seeing if a person can get hypertension with age

ggplot(data = stroke_1, aes(
  x = as.character(prevalentHyp),
  y = age,
  fill = stroke
)) +
  geom_boxplot() +
  labs(title = "Age distribution by hypertension", x = "hypertension", y = "age") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

This Box plot that we created for the combination of hypertension and age (the person who was affected by heart stroke), where hypertension - 0 represents people who did not have hypertension and hypertension-1 represents people who did have hypertension. 

According to the graph,those who in the age netween 50 to 60 years and  those with hypertension are more likely to have a heart attack.

### Does BMI alone cause stroke?
```{r BMI_stroke_1, include=TRUE, echo=TRUE}
# BMI category vs stroke count

ggplot(dat_1, aes(x = BMI.cat, fill = stroke)) +
  geom_bar() +
  labs(x = "BMI Category", y = "Count", title = "Distribution of Stroke Cases by BMI Category") +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

This bar plot that we plotted for BMI and the person who effected with heart stroke. 

We converted BMI as a categorical variable into several groups like (underweight, normal, overweight,obesity,severe obesity) as per our observation the people who are in the overweight category are the most people who had influenced heart attack.

### Distribution of Age by Stroke Status.
```{r stroke_1_age, include=TRUE, echo=TRUE}
ggplot(stroke_1, aes(x = age, fill = stroke)) +
  geom_histogram(binwidth = 5, position = "dodge") +
  labs(x = "Age", y = "Count", title = "Distribution of Age by Stroke Status") +
  scale_x_continuous(breaks = seq(0, 100, by = 5)) +
  scale_fill_discrete(name = "stroke", labels = c("1 - Yes"))
```

This histogram plot type was created for the combination of age and stroke count; it informs us that the older we get, the more individuals are affected by stroke.

### Does BMI and Glucose together cause stroke?
```{r BMI_glucose_stroke_1, include=TRUE, echo=TRUE}
ggplot(stroke_1, aes(x = BMI, y = glucose, color = stroke)) +
  geom_point(alpha = 0.7) +
  labs(x = "BMI", y = "Glucose Level", title = "Relationship between BMI and Glucose Levels who had stroke") +
  scale_color_manual(values = c("lightblue", "red")) +
  scale_color_discrete(name = "stroke", labels = c("1 - Yes"))
```

This scatter plot depicts the relationship between BMI and Glucose level in stroke patients. 

In the plot, the x-axis (BMI) ranges from 0 to 60 and y-axis (glucose level) ranges from 50 to 400. People with a BMI of 20 to 30 range and a glucose level of less than 100 are recorded as the most number of people who are affected with the stroke.


### How sysBP and diaBP along with age groups together cause stroke?
```{r sysBP_diaBP_age_stroke_1, include=TRUE, echo=TRUE}
ggplot(dat_1, aes(x = sysBP, y = diaBP, color = age)) +
  geom_point() +
  labs(
    title = "Scatter plot of systolic vs diastolic blood pressure of people who had stroke",
    x = "Systolic BP",
    y = "Diastolic BP",
    color = "Age"
  ) +
  scale_color_gradient(low = "blue", high = "red")
```

This scatter plot depicts the relationship between Systolic Blood pressure and Diastolic Blood pressure in stroke patients. 

In the plot, the x-axis (Systolic BP) ranges from 50 to 300 and y-axis (Diastolic BP) ranges from 50 to 150. 

People with a Systolic BP of 100 to 150 range and a Diastolic BP of 60 to 100 are recorded as the most number of people who are affected with the stroke in the age group of 40 to 50.


# Hypothesis testing

Null Hypothesis (H0) = There is no relationship between the predictor variables (Age, Hypertension, SysBP, DiaBP â€¦) and the outcome of stroke occurrence.

Alternate Hypothesis (H1/Ha) = there is a relationship between at least one of the predictor variables as a risk factor and the outcome.

## Statistical Chi-Square test for predictor variables (categorical) with target variable (Stroke)
For categorical variables, we are calculating p-vlaue using chi-square test.

### chi square test for gender
```{r Chi-Square-test}
gender_chi_res <- chisq.test(stroke_df$stroke, stroke_df$gender)
gender_chi_res
```

### chi square test for currentSmoker
```{r}
currentSmoker_chi_res <- chisq.test(stroke_df$stroke, stroke_df$currentSmoker)
currentSmoker_chi_res
```

### chi square test for prevalentStroke
```{r}
prevalentStroke_chi_res <- chisq.test(stroke_df$stroke, stroke_df$prevalentStroke)
prevalentStroke_chi_res
```

### chi square test for prevalentHyp
```{r}
prevalentHyp_chi_res <- chisq.test(stroke_df$stroke, stroke_df$prevalentHyp)
prevalentHyp_chi_res
```

### chi square test for diabetes
```{r}
diabetes_chi_res <- chisq.test(stroke_df$stroke, stroke_df$diabetes)
diabetes_chi_res
```


## Statistical t-test for predictor variables (numerical) with target variable (Stroke)
For numerical variables, we are calculating p-vlaue using t-test.


### t-test for totChol
```{r totChol_t_test}
totChol_t_test <- t.test(totChol ~ stroke, data = stroke_df)
totChol_t_test
```

### t-test for sysBP
```{r sysBP_t_test}
sysBP_t_test <- t.test(sysBP ~ stroke, data = stroke_df)
sysBP_t_test
```

### t-test for diaBP
```{r diaBP_t_test}
diaBP_t_test <- t.test(diaBP ~ stroke, data = stroke_df)
diaBP_t_test
```

### t-test for BMI
```{r BMI_t_test}
BMI_t_test <- t.test(BMI ~ stroke, data = stroke_df)
BMI_t_test
```

### t-test for age
```{r age_t_test}
age_t_test <- t.test(age ~ stroke, data = stroke_df)
age_t_test
```

### t-test for glucose
```{r glucose_t_test}
glucose_t_test <- t.test(glucose ~ stroke, data = stroke_df)
glucose_t_test
```
# Conclusions from EDA:
As we can see from the analysis with evidences, the p values for both tests are less than the level of significance (chosen 0.05), 
and with the strong evidence from both the statistical tests, we are rejecting the null hypothesis and accepting the alternate hypothesis.

As per this data the chances of hypertension, diastolic BP and systolic BP in a person is higher when he/she is older which can lead to a stroke.


# Findings:
As from the distribution plot of the target variable, which clearly depicts that the dataset is considered to be im-balanced and this required suitable sampling methods in order to prepare the data for the model building.


# Addressing data im-balance issue:
These lines of code are used to split the dataset into training and testing sets using the createDataPartition function from the caret package in R.
createDataPartition function is used to create a stratified random sample of the stroke variable, with a 70/30 split for the training and testing datasets respectively. 

```{r train_test_data_split, echo = TRUE}

set.seed(123)

train_index <- createDataPartition(stroke_df$stroke, p = 0.7, 
                                   list = FALSE, times = 1)

train_data <- stroke_df[train_index, ]
test_data <- stroke_df[-train_index, ]

```

Since the classes are not balanced (0=3594, 1=644), I will use SMOTE to balance the train data since if we treat them as they are, our model will predict on the class that is in the majority, which will be biased.


```{r train_data_SMOTE, echo=TRUE}


# Count the number of observations in each class before SMOTE
print("Distribution of target variable in train data before SMOTE technique: ")
print(table(train_data$stroke))

# Apply SMOTE to balance the classes
train_data_balanced <- DMwR::SMOTE(stroke ~ ., 
                             train_data, 
                             perc.over = 300, 
                             perc.under = 140)

# Count the number of observations in each class after SMOTE
print("Distribution of target variable in train data after SMOTE technique: ")
print(table(train_data_balanced$stroke))

print(paste("Total number of observations in balanced train data: ", nrow(train_data_balanced)))

```

Before applying SMOTE, there were 2516 observations with stroke=0 and 451 observations with stroke=1 in the training data. After applying SMOTE to balance the classes, there were 1894 observations with stroke=0 and 1804 observations with stroke=1 in the balanced training data.

The total number of observations in the balanced training data is 3698, which is higher than the original training data because SMOTE creates synthetic data points to balance the classes.

## Distribution of the target variable (stroke) after balancing
```{r target_var_balanced, include=TRUE, echo=TRUE}

ggplot(train_data_balanced, aes(x = stroke)) +
  geom_bar(aes(fill = ..count..)) +
  scale_fill_gradient("Count", low = "#F0E442", high = "#999999") +
  labs(x = "stroke", y = "Count of People", title = "Distribution of Target variable (stroke) in Train data")

```

## Model Building with Balanced data with all features
### Model Building - 1: Decision Tree

```{r decision_tree_model_bal, echo = TRUE}

library(rpart)

# Fit decision tree model
tree_model_bal <- rpart(stroke ~ ., 
                    data = train_data_balanced, 
                    method="class")


# Make predictions on the test data
test_preds <- predict(tree_model_bal, 
                      test_data, 
                      type="class")


# print confusion matrix
dt_confusion_mat <- confusionMatrix(factor(test_preds, levels = c(0, 1)), 
                                 factor(test_data$stroke, levels = c(0, 1)), 
                                 mode = 'everything')

print("Confusion matrix from decision tree: ")
print(dt_confusion_mat$table)

# calculate model performance metrics
accuracy <- dt_confusion_mat$overall['Accuracy']
precision <- dt_confusion_mat$byClass['Pos Pred Value']
sensitivity <- dt_confusion_mat$byClass['Sensitivity']
specificity <- dt_confusion_mat$byClass['Specificity']
f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)

# print performance metrics
print(paste("Accuracy: ", round(accuracy, 4) * 100, "%"))
print(paste("Precision: ", round(precision, 4) * 100, "%"))
print(paste("Recall (Sensitivity): ", round(sensitivity, 4) * 100, "%"))
print(paste("Specificity: ", round(specificity, 4) * 100, "%"))
print(paste("F1 Score: ", round(f1_score, 4) * 100, "%"))


# AUC-ROC curve
library(pROC)

prob_dt <- predict(tree_model_bal, 
                test_data,
                type = "prob")

ROC_dt <- roc(test_data$stroke, 
              prob_dt[,2])

auc_val_dt <- auc(ROC_dt)

plot(ROC_dt, 
     print.auc = TRUE, 
     print.auc.x = 0.5, 
     print.auc.y = 0.2)

```


```{r decision_tree_model_bal_map, echo = TRUE}

# decision tree fit
fit <- rpart(stroke ~ .
             , data = train_data_balanced, 
             method = 'class')

rpart.plot(fit, extra = 106)

```

The model is based on a dataset with 3698 instances, where each instance has a set of attributes and a binary class label (0 or 1).

The root node is the starting point of the tree, and it includes all 3698 instances. The root node split the data based on the "age" attribute. If the age is less than 47.02149, the data goes to node 2; otherwise, it goes to node 3.

Node 2 includes 1165 instances with the age less than 47.02149, and it further splits the data based on the "diabetes" attribute. If the diabetes is 0, the instance belongs to node 4, which includes 1124 instances with 0 class labels, and it is marked as a terminal node with a "*." If the diabetes is 1, the instance belongs to node 5, which includes 41 instances with 1 class label, and it is also marked as a terminal node.

Node 3 includes 2533 instances with the age greater than or equal to 47.02149, and it further splits the data based on the "cigsPerDay" attribute. If the cigsPerDay is less than 0.01949676, the instance belongs to node 6, which includes 853 instances with 0 class labels and marked as a terminal node. If the cigsPerDay is greater than or equal to 0.01949676, the instance belongs to node 7, which includes 1680 instances with 1 class labels.

Node 7 further splits the data based on the "cigsPerDay" attribute. If the cigsPerDay is greater than or equal to 19.96676, the instance belongs to node 14, which includes 377 instances with 0 class labels and marked as a terminal node. Otherwise, the instance belongs to node 15, which includes 1303 instances with 1 class labels and marked as a terminal node.

The output also provides some statistics for each node, including the number of instances (n), the number of instances with the class label 0 (loss), the predicted class label (yval), and the probability of each class (yprob).


```{r test_data, echo=TRUE}

# Count the number of observations in each class before SMOTE
table(test_data$stroke)

test_data_balanced <- test_data

# # Apply SMOTE to balance the classes
# test_data_balanced <- SMOTE(stroke ~ .,
#                              test_data,
#                              perc.over = 300,
#                              perc.under = 130)
# 
# # Count the number of observations in each class after SMOTE
# table(test_data_balanced$stroke)
# 
print(paste("Number of observations in test data split: ", nrow(test_data_balanced)))

```

After applying SMOTE to balance the classes in the test data, the resulting number of observations in each class is 1078 and 193 for stroke = 0 and stroke = 1 respectively. There are a total of 1271 observations in the test data.


### Tuned Decision Tree with all variables

```{r tuned_decision_tree_bal, echo = TRUE}

control <- rpart.control(minsplit = 7,
                          minbucket = round(5 / 3),
                          maxdepth = 4,
                          cp = 0)

tune_fit <- rpart(stroke ~ ., 
                  data = train_data_balanced, 
                  method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)


# Prediction
predict_unseen1 <-predict(tune_fit, 
                          test_data, 
                          type = 'class')

# Eval Metric
confusion1= confusionMatrix(predict_unseen1,
                            test_data$stroke,
                            mode= "everything")

confusion1

# AUC-ROC curve

prob = predict(tune_fit, 
               test_data,
               type="prob")

ROC_dt_tune <- roc(test_data$stroke, prob[,2])
auc_val_dt_tune <- auc(ROC_dt_tune)
auc_val_dt_tune

plot(ROC_dt_tune, 
     print.auc = TRUE, 
     print.auc.x = 0.5, 
     print.auc.y = 0.2)

```

<!-- #### Tuned Decision Tree with Feature Selection  -->

<!-- ```{r decision_tree_tuned_feat, echo = TRUE} -->

<!-- control <- rpart.control(minsplit = 7, -->
<!--     minbucket = round(5 / 3), -->
<!--     maxdepth = 4, -->
<!--     cp = 0) -->

<!-- tune_fit <- rpart(stroke ~ ., -->
<!--                   data = train_data_balanced,  -->
<!--                   method = 'class',  -->
<!--                   control = control) -->

<!-- rpart.plot(tune_fit,  -->
<!--            extra = 106) -->

<!-- # prediction -->
<!-- predict_unseen1 <-predict(tune_fit, test_data, type = 'class') -->

<!-- # Evaluation Metric -->
<!-- confusion1= confusionMatrix(predict_unseen1, -->
<!--                             test_data$stroke, -->
<!--                             mode= "everything") -->

<!-- confusion1 -->

<!-- # AUC-ROC curve -->

<!-- prob <- predict(tune_fit,  -->
<!--                 test_data,  -->
<!--                 type="prob") -->

<!-- ROC_rf <- roc(test_data$stroke, prob[,2]) -->
<!-- plot(ROC_rf) -->
<!-- paste("Area under curve of random forest: ", auc(ROC_rf)) -->

<!-- ``` -->


### Model building - 2: Random Forest
```{r rf_model_bal, echo = TRUE}

rf_model_bal <- randomForest(stroke ~ .,
                         data = train_data_balanced,
                         importance = TRUE)

# make predictions on test data
test_preds_rf <- predict(rf_model_bal, 
                         newdata = test_data)

# calculate accuracy
rf_model_accuracy <- sum(test_preds_rf == test_data$stroke) / nrow(test_data)

# calculate feature importance
rf_importance <- importance(rf_model_bal)
print(rf_importance)

# plot feature importance
varImpPlot(rf_model_bal, type = 2, main = "Random Forest Feature Importance")

rf_importance <- as.data.frame(rf_importance)

rf_importance <- rf_importance[order(rf_importance$MeanDecreaseGini, 
                                     decreasing = TRUE),]


# AUC-ROC curve for RF model

prob_rf <- predict(rf_model_bal, 
                test_data,
                type = "prob")

ROC_rf <- roc(test_data$stroke, 
              prob_rf[,2])

auc_val_rf <- auc(ROC_rf)

plot(ROC_rf, 
     print.auc = TRUE, 
     print.auc.x = 0.5, 
     print.auc.y = 0.2)

```

### Random forest model evaluation metrics on balanced data
```{r rf_model_bal_evaluation_metrics, echo = TRUE}

# create confusion matrix
confusion_mat_rf <- confusionMatrix(data = test_preds_rf, 
                                      reference = test_data$stroke)

# print accuracy
full_model_accuracy <- confusion_mat_rf$overall['Accuracy']
print(paste("Accuracy: ", round(full_model_accuracy, 4) * 100, "%"))


# print precision
full_model_precision <- confusion_mat_rf$byClass['Pos Pred Value']
print(paste("Precision: ", round(full_model_precision, 4) * 100, "%"))

# print recall (sensitivity)
full_model_sensitivity <- confusion_mat_rf$byClass['Sensitivity']
print(paste("Recall (Sensitivity): ", round(full_model_sensitivity, 4) * 100, "%"))

# print specificity
full_model_specificity <- confusion_mat_rf$byClass['Specificity']
print(paste("Specificity: ", round(full_model_specificity, 4) * 100, "%"))

# print F1 score
full_model_f1_score <- 2 * (confusion_mat_rf$byClass['Pos Pred Value'] * confusion_mat_rf$byClass['Sensitivity']) / (confusion_mat_rf$byClass['Pos Pred Value'] + confusion_mat_rf$byClass['Sensitivity'])

print(paste("F1 Score: ", round(full_model_f1_score, 4) * 100, "%"))

```


### Model building 3: Logistic Regression with feature selection
```{r glm_model_bal_feat, echo = TRUE}

# Fit a logistic regression model to the training data
glm_model_bal_feat <- glm(stroke ~ diaBP + sysBP + age + glucose + BMI + totChol +
                               cigsPerDay + heartRate + prevalentHyp + currentSmoker, 
                 family = binomial, 
                 data = train_data_balanced)


print(summary(glm_model_bal_feat))

# Make predictions on the testing data
glm_test_preds <- predict(glm_model_bal_feat, 
                      newdata = test_data, 
                      type = "response")

# Calculate the accuracy of the model
glm_test_preds_acc <- ifelse(glm_test_preds > 0.5, 1, 0)

```

The summary of the logistic regression model fitted on the training data shows the following:

The coefficients table shows the estimated effect of each predictor on the log odds of having a stroke. For example, for every one-unit increase in "sysBP", the log odds of having a stroke increase by 0.0157. The intercept represents the log odds of having a stroke when all the predictors are equal to zero.

The "Pr(>|z|)" column in the coefficients table shows the p-values for testing the null hypothesis that the true value of the coefficient is zero. For example, the coefficient for "totChol" is statistically significant at the 0.05 level, meaning that there is evidence to suggest that it has a non-zero effect on the log odds of having a stroke.

The "Deviance Residuals" table shows the distribution of the residuals (i.e., the differences between the predicted probabilities and the actual outcomes) after fitting the model. The values should be symmetrically distributed around zero, with no obvious patterns or trends.

The "Null deviance" and "Residual deviance" values provide information about the overall goodness of fit of the model. The null deviance represents the deviance of a model with no predictors, while the residual deviance represents the deviance of the fitted model. The difference between these two values provides a measure of the improvement in deviance that the model provides. In this case, the residual deviance is lower than the null deviance, indicating that the model has some predictive power.

The AIC value provides a measure of the model's goodness of fit, while taking into account the number of parameters in the model. A lower AIC value indicates a better fit.

The "Number of Fisher Scoring iterations" provides information about the number of iterations required to fit the model. This is an internal measure of the algorithm used to fit the model and does not provide any meaningful information about the model itself.

```{r glm_model_bal_feat_VIF, echo=TRUE}

vif(glm_model_bal_feat)

```


The output of VIF (Variance Inflation Factor) provides an indication of the degree of multicollinearity in a regression model. 
A VIF value of 1 indicates no multicollinearity, whereas higher values indicate increasing levels of multicollinearity. 
In general, VIF values above 5 or 10 indicate a problematic level of multicollinearity.

In this case, all VIF values are less than 5, which indicates that there is not a significant problem with multicollinearity in the model.

```{r glm_model_bal_feat_eval_metrics, echo = TRUE}

# create confusion matrix
glm_model_confusion_mat <- confusionMatrix(factor(glm_test_preds_acc, 
                                        levels = c(0, 1)), 
                               factor(test_data_balanced$stroke, 
                                      levels = c(0, 1)))

# print the confusion matrix
print(glm_model_confusion_mat$table)


# print accuracy
accuracy <- glm_model_confusion_mat$overall['Accuracy']
print(paste("Accuracy: ", round(accuracy, 4) * 100, "%"))


# print precision
precision <- glm_model_confusion_mat$byClass['Pos Pred Value']
print(paste("Precision: ", round(precision, 4) * 100, "%"))


# print recall (sensitivity)
sensitivity <- glm_model_confusion_mat$byClass['Sensitivity']
print(paste("Recall (Sensitivity): ", round(sensitivity, 4) * 100, "%"))


# print specificity
specificity <- glm_model_confusion_mat$byClass['Specificity']
print(paste("Specificity: ", round(specificity, 4) * 100, "%"))


# print F1 score
f1_score <- 2 * (glm_model_confusion_mat$byClass['Pos Pred Value'] * glm_model_confusion_mat$byClass['Sensitivity']) / (glm_model_confusion_mat$byClass['Pos Pred Value'] + glm_model_confusion_mat$byClass['Sensitivity'])

print(paste("F1 Score: ", round(f1_score, 4) * 100, "%"))

```

This is the output of a logistic regression model's predictions on a binary classification problem with the response variable taking two values: 0 and 1. The output shows a confusion matrix where the rows represent the predicted values of the model, and the columns represent the true values.

The confusion matrix shows that the model predicted 800 true negatives (TN), 97 false positives (FP), 278 false negatives (FN), and 96 true positives (TP).

The accuracy of the model is calculated as the proportion of correct predictions to the total number of predictions, which is (800+96)/(800+97+278+96) = 0.705, or 70.5%.

The precision of the model is calculated as the proportion of true positives to the total number of predicted positives, which is 96/(97+96) = 0.8919, or 89.19%. This metric represents the proportion of correctly identified positives out of all the positives that the model predicted.

The recall (or sensitivity) of the model is calculated as the proportion of true positives to the total number of actual positives, which is 96/(278+96) = 0.7421, or 74.21%. This metric represents the proportion of actual positives that the model correctly identified.

The specificity of the model is calculated as the proportion of true negatives to the total number of actual negatives, which is 800/(800+97) = 0.4974, or 49.74%. This metric represents the proportion of actual negatives that the model correctly identified.

The F1 score is the harmonic mean of precision and recall and is calculated as 2 * (precisionrecall)/(precision+recall). In this case, it is 2(0.8919 * 0.7421) / (0.8919 + 0.7421) = 0.8101, or 81.01%. This metric provides a single score that balances both precision and recall.




```{r glm_model_bal_feat_AUC_curve, echo = TRUE}

prob_glm_ft <- predict(glm_model_bal_feat, 
                test_data,
                type = "response")

ROC_glm_ft <- roc(test_data$stroke, 
                  prob_glm_ft)

auc_val_glm_ft <- auc(ROC_glm_ft)

plot(ROC_glm_ft, 
     print.auc = TRUE, 
     print.auc.x = 0.5, 
     print.auc.y = 0.2)

```


### Model building 2: Using step() for all variables
```{r glm_full_model_bal, echo = TRUE}

# Fit a logistic regression full model to the training data
glm_full_model <- glm(stroke ~ ., 
                 family = binomial, 
                 data = train_data_balanced)

print(summary(glm_full_model))

```


```{r glm_full_step_model, echo = TRUE}

# Perform stepwise regression using the "step" function
glm_full_step_model <- step(glm_full_model)

print(summary(glm_full_step_model))

# Make predictions on the testing data
test_preds_glm <- predict(glm_full_step_model, 
                      newdata = test_data, 
                      type = "response")

# Calculate the accuracy of the model
test_full_preds_acc <- ifelse(test_preds_glm > 0.5, 1, 0)

```

Based on the summary output, we can see that several variables are statistically significant in predicting stroke based on the p-values of their corresponding coefficients (i.e., have p-values less than 0.05). These variables are:

gender
age
cigsPerDay
prevalentStroke
prevalentHyp
sysBP
glucose

The coefficients of these variables have positive values which has a positive coefficient value, indicating that as the values of these variables increase, the likelihood of having a stroke also increases.

However, we should note that some variables are not statistically significant, such as education, currentSmoker, BPMeds, diabetes, totChol, diaBP, BMI, and heartRate, as their p-values are greater than 0.05.

```{r glm_full_step_model_vif, echo=TRUE}

vif(glm_full_step_model)

```

From the VIF values, we can see that all the VIF values are below the commonly accepted threshold of 5, indicating that multicollinearity is not a major concern in this model.

```{r glm_full_model_eval_metrics, echo = TRUE}

# create confusion matrix
confusion_mat_full <- confusionMatrix(factor(test_full_preds_acc, levels = c(0, 1)), 
                               factor(test_data$stroke, levels = c(0, 1)))

# print the confusion matrix
confusion_mat_full$table


# print accuracy
full_model_accuracy <- confusion_mat_full$overall['Accuracy']
print(paste("Accuracy: ", round(full_model_accuracy, 4) * 100, "%"))

# print precision
full_model_precision <- confusion_mat_full$byClass['Pos Pred Value']
print(paste("Precision: ", round(full_model_precision, 4) * 100, "%"))

# print recall (sensitivity)
full_model_sensitivity <- confusion_mat_full$byClass['Sensitivity']
print(paste("Recall (Sensitivity): ", round(full_model_sensitivity, 4) * 100, "%"))

# print specificity
full_model_specificity <- confusion_mat_full$byClass['Specificity']
print(paste("Specificity: ", round(full_model_specificity, 4) * 100, "%"))

# print F1 score
full_model_f1_score <- 2 * (confusion_mat_full$byClass['Pos Pred Value'] * confusion_mat_full$byClass['Sensitivity']) / (confusion_mat_full$byClass['Pos Pred Value'] + confusion_mat_full$byClass['Sensitivity'])

print(paste("F1 Score: ", round(full_model_f1_score, 4) * 100, "%"))

```


### Model evaluation metrics and confusion metrics:
Based on the metrics:

From this confusion matrix, we can see that the model predicted 867 true negatives, 83 true positives, 211 false negatives, and 110 false positives.

Accuracy: the proportion of correctly classified observations over the total number of observations. The accuracy of the full model is 74.74%, which means that 74.74% of the stroke cases were correctly classified.

Precision: the proportion of true stroke cases over all predicted stroke cases. The precision of the full model is 88.78%, which means that 88.78% of the predicted stroke cases were actually stroke cases.

Recall (Sensitivity): the proportion of true stroke cases over all actual stroke cases. The recall of the full model is 80.43%, which means that 80.43% of the actual stroke cases were correctly identified by the model.

Specificity: the proportion of true non-stroke cases over all actual non-stroke cases. The specificity of the full model is 43.01%, which means that only 43.01% of the actual non-stroke cases were correctly identified by the model.

F1 Score: the harmonic mean of precision and recall. The F1 score of the full model is 84.38%, which provides a balanced view of the model's performance in terms of both precision and recall.


```{r logit_full_step_model_ROC_curve, echo = TRUE}

prob_log_step <- predict(glm_full_step_model, 
                test_data,
                type = "response")

ROC_log_step <- roc(test_data$stroke, prob_log_step)
auc_val_log_step <- auc(ROC_log_step)

plot(ROC_log_step, 
     print.auc = TRUE, 
     print.auc.x = 0.5, 
     print.auc.y = 0.2)

```

## AUC-ROC Curve interpretation for logistic regression with step model

An AUC of 0.5 indicates that the model is no better than random guessing, while an AUC of 1.0 indicates perfect predictive power.
The AUC (Area Under the Curve) of the ROC (Receiver Operating Characteristic) curve is 0.7119, indicating that the model has a moderate ability to distinguish between stroke and non-stroke cases.

